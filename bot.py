import logging
import os
import requests
import pandas as pd
import datetime
import pytz
import asyncio
import json
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
TOKEN = os.getenv('BOT_TOKEN')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö
SUBSCRIBERS_FILE = "subscribers.txt"
COMPANIES_FILE = "companies.txt"
HISTORY_FILE = "history.json"  # <--- –ù–û–í–´–ô –§–ê–ô–õ –î–õ–Ø –ò–°–¢–û–†–ò–ò

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
DATASET_ID = '544d4dad-0b6d-4972-b0b8-fb266829770f'
BACKUP_URL = 'https://data.gov.ua/dataset/544d4dad-0b6d-4972-b0b8-fb266829770f/resource/deb76481-a6c8-4a45-ae6c-f02aa87e9f4a/download/vidomosti-pro-spravi-pro-bankrutstvo.csv'
DAYS_TO_CHECK = 365 

# --- –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° –ò–°–¢–û–†–ò–ï–ô (–ù–û–í–û–ï) ---

def load_history():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —É–∂–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –±–∞–Ω–∫—Ä–æ—Ç—Å—Ç–≤."""
    if not os.path.exists(HISTORY_FILE):
        return []
    try:
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        return []

def save_history(history_list):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é."""
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history_list, f, ensure_ascii=False, indent=4)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")

# --- –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° –î–ê–ù–ù–´–ú–ò ---

def get_monitored_codes():
    if not os.path.exists(COMPANIES_FILE):
        return []
    try:
        with open(COMPANIES_FILE, 'r', encoding='utf-8') as f:
            codes = [line.strip() for line in f if line.strip()]
        return list(set(codes)) # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    except Exception:
        return []

def get_subscribers():
    if not os.path.exists(SUBSCRIBERS_FILE):
        return set()
    try:
        with open(SUBSCRIBERS_FILE, 'r') as f:
            return set(line.strip() for line in f if line.strip())
    except Exception:
        return set()

def add_subscriber(chat_id):
    subs = get_subscribers()
    if str(chat_id) not in subs:
        with open(SUBSCRIBERS_FILE, 'a') as f:
            f.write(f"{chat_id}\n")
        return True
    return False

def remove_subscriber(chat_id):
    subs = get_subscribers()
    if str(chat_id) in subs:
        subs.remove(str(chat_id))
        with open(SUBSCRIBERS_FILE, 'w') as f:
            f.write('\n'.join(subs) + '\n')
        return True
    return False

def get_resource_url():
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    try:
        package_url = f'https://data.gov.ua/api/3/action/package_show?id={DATASET_ID}'
        response = requests.get(package_url, headers=headers, timeout=15, verify=False)
        data = response.json()
        if data.get('success'):
            return data['result']['resources'][-1]['url']
    except Exception:
        pass
    return BACKUP_URL

def check_bankruptcy_logic():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞: 
    1. –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª
    2. –ò—â–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    3. –§–∏–ª—å—Ç—Ä—É–µ—Ç —á–µ—Ä–µ–∑ history.json (—Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ)
    """
    enterprise_codes = get_monitored_codes()
    if not enterprise_codes:
        return "‚ö†Ô∏è –§–∞–π–ª companies.txt –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω."

    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
    url = get_resource_url()
    local_filename = "bankruptcy_temp.csv"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    try:
        response = requests.get(url, headers=headers, stream=True, timeout=120, verify=False)
        response.raise_for_status()
        with open(local_filename, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
    except Exception as e:
        return f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ä–µ–µ—Å—Ç—Ä: {str(e)[:100]}"

    # –ß—Ç–µ–Ω–∏–µ
    data_df = None
    for enc in ["utf-8", "cp1251", "windows-1251", "latin-1"]:
        try:
            data_df = pd.read_csv(local_filename, sep=None, engine="python", on_bad_lines="skip", encoding=enc, encoding_errors='replace')
            break
        except:
            continue
    
    if data_df is None:
        if os.path.exists(local_filename): os.remove(local_filename)
        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV (–ø—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π)."

    # –û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫
    data_df.columns = data_df.columns.str.strip()
    
    edrpou_col = next((col for col in data_df.columns if '–∫–æ–¥' in col.lower() or 'edrpou' in col.lower()), 'firm_edrpou')
    name_col = next((col for col in data_df.columns if '–Ω–∞–∑–≤–∞' in col.lower() or 'name' in col.lower()), data_df.columns[1])
    date_col = next((col for col in data_df.columns if '–¥–∞—Ç–∞' in col.lower() or 'date' in col.lower()), None)

    if edrpou_col not in data_df.columns or not date_col:
        if os.path.exists(local_filename): os.remove(local_filename)
        return "‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞ (–Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –∫–æ–¥–∞ –∏–ª–∏ –¥–∞—Ç—ã)."

    data_df['clean_code'] = data_df[edrpou_col].astype(str).str.strip()
    date_threshold = datetime.date.today() - datetime.timedelta(days=DAYS_TO_CHECK)

    # --- –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ù–û–í–´–• –ó–ê–ü–ò–°–ï–ô ---
    
    seen_history = load_history() # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ ["–∫–æ–¥_–¥–∞—Ç–∞", "–∫–æ–¥_–¥–∞—Ç–∞"...]
    history_set = set(seen_history) # –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    
    new_results = []
    new_history_entries = []

    for code in enterprise_codes:
        matches = data_df[data_df['clean_code'] == code]
        if not matches.empty:
            row = matches.iloc[0] # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å
            
            date_val = str(row[date_col]).strip()
            if pd.isna(date_val) or date_val.lower() == 'nan': continue
            
            # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã
            try:
                clean_date_str = date_val.split()[0]
                date_obj = datetime.datetime.strptime(clean_date_str, "%d.%m.%Y").date()
            except:
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É
            if date_obj > date_threshold:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è —ç—Ç–æ–π –∑–∞–ø–∏—Å–∏: "–ö–û–î_–î–ê–¢–ê"
                # –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –æ—Ç–ª–∏—á–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –¥–µ–ª–∞ –ø–æ –æ–¥–Ω–æ–π –∫–æ–º–ø–∞–Ω–∏–∏, –µ—Å–ª–∏ –¥–∞—Ç—ã —Ä–∞–∑–Ω—ã–µ
                unique_id = f"{code}_{clean_date_str}"
                
                # –ï–°–õ–ò –≠–¢–û–ì–û ID –ù–ï–¢ –í –ò–°–¢–û–†–ò–ò -> –≠–¢–û –ù–û–í–û–ï!
                if unique_id not in history_set:
                    new_results.append({
                        "code": code,
                        "name": str(row[name_col]),
                        "date": clean_date_str,
                        "date_obj": date_obj
                    })
                    new_history_entries.append(unique_id)

    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
    if os.path.exists(local_filename):
        os.remove(local_filename)

    # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    if new_results:
        # 1. –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –Ω–∞ –¥–∏—Å–∫–µ
        seen_history.extend(new_history_entries)
        save_history(seen_history)
        
        # 2. –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        new_results.sort(key=lambda x: x["date_obj"], reverse=True)
        message = f"üî• <b>–ù–û–í–´–ï –ë–ê–ù–ö–†–û–¢–°–¢–í–ê ({len(new_results)})</b>\n\n"
        for i, entry in enumerate(new_results, 1):
            name = entry['name'][:100] + "..." if len(entry['name']) > 100 else entry['name']
            message += (
                f"{i}. <b>{entry['code']}</b>\n"
                f"üè¢ {name}\n"
                f"üìÖ {entry['date']}\n"
                f"{'-'*20}\n"
            )
        return message
    else:
        return "‚úÖ –ù–æ–≤—ã—Ö –±–∞–Ω–∫—Ä–æ—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (—Å—Ä–µ–¥–∏ —Ç–µ—Ö, –∫–æ–≥–æ –≤—ã –µ—â–µ –Ω–µ –≤–∏–¥–µ–ª–∏)."

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    add_subscriber(chat_id)
    await update.message.reply_text("üîî –í—ã –ø–æ–¥–ø–∏—Å–∞–Ω—ã! –Ø –±—É–¥—É –ø—Ä–∏—Å—ã–ª–∞—Ç—å –¢–û–õ–¨–ö–û –Ω–æ–≤—ã—Ö –±–∞–Ω–∫—Ä–æ—Ç–æ–≤.")

async def manual_check(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("‚è≥ –ò—â—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ —Ä–µ–µ—Å—Ç—Ä–µ...")
    report = await asyncio.to_thread(check_bankruptcy_logic)
    
    # –†–∞–∑–±–∏–≤–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    if len(report) > 4000:
        for x in range(0, len(report), 4000):
            await update.message.reply_text(report[x:x+4000], parse_mode='HTML')
    else:
        await update.message.reply_text(report, parse_mode='HTML')

async def scheduled_check(context: ContextTypes.DEFAULT_TYPE):
    subs = get_subscribers()
    if not subs: return
    
    logger.info("–ê–≤—Ç–æ-–ø—Ä–æ–≤–µ—Ä–∫–∞...")
    report = await asyncio.to_thread(check_bankruptcy_logic)
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–æ–≤–æ–≥–æ ("‚úÖ –ù–æ–≤—ã—Ö –±–∞–Ω–∫—Ä–æ—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ..."), –≤ –∞–≤—Ç–æ-—Ä–µ–∂–∏–º–µ –º–æ–ª—á–∏–º
    # –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø–æ–ª—É—á–∞—Ç—å –æ—Ç—á–µ—Ç "–≤—Å–µ –æ–∫" –∫–∞–∂–¥—ã–π –¥–µ–Ω—å - —É–±–µ—Ä–∏—Ç–µ —É—Å–ª–æ–≤–∏–µ –Ω–∏–∂–µ
    if "‚úÖ" in report:
        return 

    for chat_id in subs:
        try:
            if len(report) > 4000:
                for x in range(0, len(report), 4000):
                    await context.bot.send_message(chat_id=chat_id, text=report[x:x+4000], parse_mode='HTML')
            else:
                await context.bot.send_message(chat_id=chat_id, text=report, parse_mode='HTML')
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ {chat_id}: {e}")

async def cleandup(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–°–∫—Ä—ã—Ç–∞—è –∫–æ–º–∞–Ω–¥–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å—ë –∑–∞–Ω–æ–≤–æ"""
    if os.path.exists(HISTORY_FILE):
        os.remove(HISTORY_FILE)
        await update.message.reply_text("üóë –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –æ—á–∏—â–µ–Ω–∞! –°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫–∞–∂–µ—Ç –í–°–ï–• –±–∞–Ω–∫—Ä–æ—Ç–æ–≤ –∫–∞–∫ –Ω–æ–≤—ã—Ö.")
    else:
        await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è —É–∂–µ –ø—É—Å—Ç–∞.")

# --- –ó–ê–ü–£–°–ö ---

if __name__ == '__main__':
    if not TOKEN:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –∑–∞–¥–∞–Ω BOT_TOKEN")
        exit()

    app = ApplicationBuilder().token(TOKEN).build()
    
    # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ (9:00 –ö–∏–µ–≤)
    jq = app.job_queue
    kyiv_tz = pytz.timezone('Europe/Kiev')
    jq.run_daily(scheduled_check, time=datetime.time(hour=9, minute=0, tzinfo=kyiv_tz))

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("check", manual_check))
    app.add_handler(CommandHandler("reset", cleandup)) # –ö–æ–º–∞–Ω–¥–∞ —Å–±—Ä–æ—Å–∞ "–ø–∞–º—è—Ç–∏"

    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω (—Ä–µ–∂–∏–º: —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ)")
    app.run_polling()
